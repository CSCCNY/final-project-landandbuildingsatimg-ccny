{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import Sequence , get_file\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler ,EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, json, shutil\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "from itertools import islice\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")    \n",
    "#     except RuntimeError as e:\n",
    "#         # Visible devices must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "    \n",
    "# tf.config.set_soft_device_placement(True)\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs,label_map , img_dir ,mode):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "        self.label_map = image_label_map\n",
    "        self.on_epoch_end()\n",
    "        self.img_dir = img_dir + \"/images\"\n",
    "        self.mask_dir = img_dir + \"/masks\"\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.list_IDs))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))    \n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index:(index+1)]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        if self.mode == \"train\":\n",
    "            # Generate data\n",
    "            X, y = self.load_file(list_IDs_temp)\n",
    "            return X, y\n",
    "        elif self.mode == \"val\":\n",
    "            X, y = self.load_file(list_IDs_temp)\n",
    "            return X, y\n",
    "        \n",
    "        \n",
    "    def load_file(self, id_list):\n",
    "        list_IDs_temp = id_list\n",
    "        for ID in list_IDs_temp:\n",
    "            x_file_path = os.path.join(self.img_dir, ID)\n",
    "            y_file_path = os.path.join(self.mask_dir, self.label_map.get(ID))\n",
    "            # Store sample\n",
    "            X = np.load(x_file_path)\n",
    "            # Store class\n",
    "            y = np.load(y_file_path).astype('float32')\n",
    "        return X, y    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "out_train_data_dir = '/glade/scratch/hgamarro/Deep_learning/HG_space/data/processed/Vegas_v1/train'\n",
    "out_val_data_dir = '/glade/scratch/hgamarro/Deep_learning/HG_space/data/processed/Vegas_v1/val'\n",
    "\n",
    "\n",
    "# ====================\n",
    "# train set\n",
    "# ====================\n",
    "all_files = [s for s in os.listdir(out_train_data_dir + \"/images/\") if s.endswith('.npy')]\n",
    "all_files.append([s for s in os.listdir(out_train_data_dir + \"/masks/\") if s.endswith('.npy')] )\n",
    "\n",
    "image_label_map = {\n",
    "        \"image_file_{}.npy\".format(i+1): \"label_file_{}.npy\".format(i+1)\n",
    "        for i in range(int(len(all_files)))}\n",
    "partition = [item for item in all_files if \"image_file\" in item]\n",
    "\n",
    "# ====================\n",
    "# validation set\n",
    "# ====================\n",
    "\n",
    "all_val_files = [s for s in os.listdir(out_val_data_dir + \"/images/\") if s.endswith('.npy')]\n",
    "all_val_files.append([s for s in os.listdir(out_val_data_dir + \"/masks/\") if s.endswith('.npy')] )\n",
    "val_image_label_map = {\n",
    "        \"image_file_{}.npy\".format(i+1): \"label_file_{}.npy\".format(i+1)\n",
    "        for i in range(int(len(all_val_files)))}\n",
    "val_partition = [item for item in all_val_files if \"image_file\" in item]\n",
    "\n",
    "\n",
    "train_generator = DataGenerator(partition,image_label_map,out_train_data_dir, \"train\")\n",
    "val_generator= DataGenerator(val_partition,val_image_label_map,out_val_data_dir, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/glade/scratch/hgamarro/Deep_learning/HG_space/models/scratch/BD_v1_results_main/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet\n"
     ]
    }
   ],
   "source": [
    "BACKBONE = 'vgg16'\n",
    "# BACKBONE = 'resnet50'\n",
    "# BACKBONE = 'efficientnetb6'\n",
    "model_name = 'Unet'\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0001\n",
    "EPOCHS = 100\n",
    "\n",
    "n_classes = 1  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    if model_name == 'Unet':\n",
    "        print(model_name)\n",
    "        model = sm.Unet(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    elif model_name == 'Linknet':\n",
    "        print(model_name)\n",
    "        model = sm.Linknet(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    elif model_name == 'FPN':\n",
    "        print(model_name)\n",
    "        model = sm.FPN(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    \n",
    "\n",
    "# define optomizer\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(save_path + BACKBONE + \"_\" + model_name + \".h5\",\n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fit\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 64 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 64 all-reduces with algorithm = nccl, num_packs = 1\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.7842 - iou_score: 0.3400 - f1-score: 0.4984 - val_loss: 1.8003 - val_iou_score: 0.2058 - val_f1-score: 0.3410\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.5850 - iou_score: 0.6433 - f1-score: 0.7817 - val_loss: 1.0188 - val_iou_score: 0.2753 - val_f1-score: 0.4313\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.5033 - iou_score: 0.7487 - f1-score: 0.8560 - val_loss: 0.6385 - val_iou_score: 0.4985 - val_f1-score: 0.6645\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.4546 - iou_score: 0.7776 - f1-score: 0.8747 - val_loss: 0.5048 - val_iou_score: 0.7394 - val_f1-score: 0.8500\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.4055 - iou_score: 0.7971 - f1-score: 0.8869 - val_loss: 0.4303 - val_iou_score: 0.7945 - val_f1-score: 0.8853\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.3613 - iou_score: 0.8172 - f1-score: 0.8993 - val_loss: 0.3854 - val_iou_score: 0.8094 - val_f1-score: 0.8945\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.3283 - iou_score: 0.8279 - f1-score: 0.9058 - val_loss: 0.3479 - val_iou_score: 0.8185 - val_f1-score: 0.9000\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.3015 - iou_score: 0.8366 - f1-score: 0.9109 - val_loss: 0.3250 - val_iou_score: 0.8098 - val_f1-score: 0.8947\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 61s 2s/step - loss: 0.2772 - iou_score: 0.8443 - f1-score: 0.9155 - val_loss: 0.2960 - val_iou_score: 0.8247 - val_f1-score: 0.9038\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.2573 - iou_score: 0.8483 - f1-score: 0.9179 - val_loss: 0.2773 - val_iou_score: 0.8262 - val_f1-score: 0.9047\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.2402 - iou_score: 0.8511 - f1-score: 0.9195 - val_loss: 0.2612 - val_iou_score: 0.8312 - val_f1-score: 0.9077\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.2218 - iou_score: 0.8583 - f1-score: 0.9237 - val_loss: 0.2466 - val_iou_score: 0.8307 - val_f1-score: 0.9073\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.2077 - iou_score: 0.8613 - f1-score: 0.9254 - val_loss: 0.2373 - val_iou_score: 0.8259 - val_f1-score: 0.9045\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.1945 - iou_score: 0.8656 - f1-score: 0.9279 - val_loss: 0.2205 - val_iou_score: 0.8371 - val_f1-score: 0.9112\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 65s 2s/step - loss: 0.1813 - iou_score: 0.8712 - f1-score: 0.9311 - val_loss: 0.2133 - val_iou_score: 0.8380 - val_f1-score: 0.9117\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.1703 - iou_score: 0.8752 - f1-score: 0.9334 - val_loss: 0.2074 - val_iou_score: 0.8392 - val_f1-score: 0.9125\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.1605 - iou_score: 0.8791 - f1-score: 0.9356 - val_loss: 0.1994 - val_iou_score: 0.8405 - val_f1-score: 0.9132\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.1510 - iou_score: 0.8837 - f1-score: 0.9382 - val_loss: 0.1936 - val_iou_score: 0.8415 - val_f1-score: 0.9138\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.1429 - iou_score: 0.8872 - f1-score: 0.9402 - val_loss: 0.1892 - val_iou_score: 0.8394 - val_f1-score: 0.9125\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.1358 - iou_score: 0.8902 - f1-score: 0.9419 - val_loss: 0.1854 - val_iou_score: 0.8407 - val_f1-score: 0.9133\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.1289 - iou_score: 0.8937 - f1-score: 0.9439 - val_loss: 0.1816 - val_iou_score: 0.8393 - val_f1-score: 0.9125\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.1230 - iou_score: 0.8966 - f1-score: 0.9454 - val_loss: 0.1828 - val_iou_score: 0.8402 - val_f1-score: 0.9131\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.1177 - iou_score: 0.8989 - f1-score: 0.9468 - val_loss: 0.1760 - val_iou_score: 0.8371 - val_f1-score: 0.9112\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.1134 - iou_score: 0.9004 - f1-score: 0.9476 - val_loss: 0.1729 - val_iou_score: 0.8366 - val_f1-score: 0.9109\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 62s 2s/step - loss: 0.1084 - iou_score: 0.9035 - f1-score: 0.9493 - val_loss: 0.1705 - val_iou_score: 0.8374 - val_f1-score: 0.9114\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.1040 - iou_score: 0.9060 - f1-score: 0.9507 - val_loss: 0.1667 - val_iou_score: 0.8369 - val_f1-score: 0.9111\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0991 - iou_score: 0.9097 - f1-score: 0.9527 - val_loss: 0.1693 - val_iou_score: 0.8397 - val_f1-score: 0.9127\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 60s 2s/step - loss: 0.0943 - iou_score: 0.9134 - f1-score: 0.9547 - val_loss: 0.1666 - val_iou_score: 0.8373 - val_f1-score: 0.9113\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0908 - iou_score: 0.9155 - f1-score: 0.9559 - val_loss: 0.1672 - val_iou_score: 0.8367 - val_f1-score: 0.9109\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0878 - iou_score: 0.9173 - f1-score: 0.9569 - val_loss: 0.1684 - val_iou_score: 0.8362 - val_f1-score: 0.9107\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0849 - iou_score: 0.9192 - f1-score: 0.9579 - val_loss: 0.1618 - val_iou_score: 0.8367 - val_f1-score: 0.9109\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 62s 2s/step - loss: 0.0810 - iou_score: 0.9226 - f1-score: 0.9597 - val_loss: 0.1635 - val_iou_score: 0.8373 - val_f1-score: 0.9113\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0780 - iou_score: 0.9248 - f1-score: 0.9609 - val_loss: 0.1608 - val_iou_score: 0.8357 - val_f1-score: 0.9104\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0756 - iou_score: 0.9264 - f1-score: 0.9618 - val_loss: 0.1611 - val_iou_score: 0.8354 - val_f1-score: 0.9102\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0739 - iou_score: 0.9271 - f1-score: 0.9622 - val_loss: 0.1604 - val_iou_score: 0.8350 - val_f1-score: 0.9100\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0723 - iou_score: 0.9279 - f1-score: 0.9626 - val_loss: 0.1601 - val_iou_score: 0.8336 - val_f1-score: 0.9091\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0707 - iou_score: 0.9287 - f1-score: 0.9630 - val_loss: 0.1606 - val_iou_score: 0.8312 - val_f1-score: 0.9077\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0683 - iou_score: 0.9307 - f1-score: 0.9641 - val_loss: 0.1598 - val_iou_score: 0.8358 - val_f1-score: 0.9104\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0651 - iou_score: 0.9341 - f1-score: 0.9659 - val_loss: 0.1593 - val_iou_score: 0.8351 - val_f1-score: 0.9100\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0638 - iou_score: 0.9347 - f1-score: 0.9663 - val_loss: 0.1615 - val_iou_score: 0.8336 - val_f1-score: 0.9091\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0630 - iou_score: 0.9349 - f1-score: 0.9664 - val_loss: 0.1612 - val_iou_score: 0.8328 - val_f1-score: 0.9087\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 58s 2s/step - loss: 0.0615 - iou_score: 0.9359 - f1-score: 0.9669 - val_loss: 0.1613 - val_iou_score: 0.8363 - val_f1-score: 0.9107\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0603 - iou_score: 0.9368 - f1-score: 0.9673 - val_loss: 0.1642 - val_iou_score: 0.8341 - val_f1-score: 0.9094\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 59s 2s/step - loss: 0.0590 - iou_score: 0.9380 - f1-score: 0.9680 - val_loss: 0.1618 - val_iou_score: 0.8317 - val_f1-score: 0.9080\n",
      "\n",
      "Time Taken for testing: 0:46:27.749204\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "print(\"Model Fit\")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_generator), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"\\nTime Taken for testing: %s\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "BACKBONE = 'vgg16'\n",
    "# BACKBONE = 'resnet50'\n",
    "# BACKBONE = 'efficientnetb6'\n",
    "# model_name = 'Unet'\n",
    "model_name = 'Linknet'\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0001\n",
    "EPOCHS = 50\n",
    "\n",
    "n_classes = 1  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    if model_name == 'Unet':\n",
    "        print(model_name)\n",
    "        model = sm.Unet(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    elif model_name == 'Linknet':\n",
    "        print(model_name)\n",
    "        model = sm.Linknet(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    elif model_name == 'FPN':\n",
    "        print(model_name)\n",
    "        model = sm.FPN(BACKBONE,classes=n_classes,input_shape=(512, 512, 3), activation=activation)\n",
    "    \n",
    "\n",
    "# define optomizer\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(save_path + BACKBONE + \"_\" + model_name + \".h5\",\n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True, \n",
    "                                    mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "print(\"Model Fit\")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_generator), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"\\nTime Taken for testing: %s\" % (end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
