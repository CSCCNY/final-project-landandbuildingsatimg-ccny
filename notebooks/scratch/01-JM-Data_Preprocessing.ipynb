{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\n",
    "\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "os.chdir('/home/juanp.montoya/NeuralNetworks/Final_Project/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 \n",
    "df1 = pd.read_csv('class_dict.csv', delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'class_dict.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 \n",
    "df2 = pd.read_csv('metadata.csv', delimiter=',', nrows = nRowsRead)\n",
    "df2.dataframeName = 'metadata.csv'\n",
    "nRow, nCol = df2.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>split</th>\n",
       "      <th>sat_image_path</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100694</td>\n",
       "      <td>train</td>\n",
       "      <td>train/100694_sat.jpg</td>\n",
       "      <td>train/100694_mask.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  split        sat_image_path              mask_path\n",
       "0    100694  train  train/100694_sat.jpg  train/100694_mask.png"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PIL.Image.open('input/train/100694_sat.jpg')\n",
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(infilename, num_files) :\n",
    "    data = np.zeros(([infilename[:num_files].shape[0], 2448, 2448, 3]))\n",
    "    for i,j in enumerate(infilename[:num_files]):\n",
    "        img = PIL.Image.open( j )\n",
    "        img.load()\n",
    "        data[i] = np.asarray( img, dtype=\"int32\" )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_image(df2.loc[df2['split'] == 'train', 'sat_image_path'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2448, 2448, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.reshape(train, [50,3,2448,2448])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected image array to have rank 3 (single image). Got array with shape: (2448, 2448)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f4d61df475b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-f9333a06010c>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(display_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NN/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NN/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError('Expected image array to have rank 3 (single image). '\n\u001b[0m\u001b[1;32m    257\u001b[0m                          'Got array with shape: %s' % (x.shape,))\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (2448, 2448)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path, file_path_mask):\n",
    "  # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "\n",
    "    mask = tf.io.read_file(file_path_mask)\n",
    "    mask = decode_img(mask)\n",
    "    return img, mask\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2448, 2448, 3), dtype=float32, numpy=\n",
       " array([[[126., 109.,  79.],\n",
       "         [127., 110.,  80.],\n",
       "         [124., 107.,  77.],\n",
       "         ...,\n",
       "         [103.,  89.,  63.],\n",
       "         [102.,  88.,  61.],\n",
       "         [102.,  88.,  61.]],\n",
       " \n",
       "        [[125., 108.,  78.],\n",
       "         [124., 107.,  77.],\n",
       "         [123., 106.,  76.],\n",
       "         ...,\n",
       "         [102.,  88.,  62.],\n",
       "         [104.,  90.,  63.],\n",
       "         [107.,  93.,  66.]],\n",
       " \n",
       "        [[123., 106.,  76.],\n",
       "         [123., 106.,  76.],\n",
       "         [125., 108.,  78.],\n",
       "         ...,\n",
       "         [106.,  92.,  66.],\n",
       "         [109.,  95.,  68.],\n",
       "         [113.,  99.,  72.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[154., 136.,  96.],\n",
       "         [156., 138.,  98.],\n",
       "         [153., 134.,  94.],\n",
       "         ...,\n",
       "         [154., 145., 102.],\n",
       "         [147., 138.,  95.],\n",
       "         [153., 144., 101.]],\n",
       " \n",
       "        [[148., 130.,  92.],\n",
       "         [150., 132.,  94.],\n",
       "         [149., 131.,  93.],\n",
       "         ...,\n",
       "         [145., 137.,  91.],\n",
       "         [133., 124.,  81.],\n",
       "         [131., 122.,  79.]],\n",
       " \n",
       "        [[148., 130.,  92.],\n",
       "         [148., 130.,  92.],\n",
       "         [148., 130.,  92.],\n",
       "         ...,\n",
       "         [136., 128.,  82.],\n",
       "         [134., 125.,  82.],\n",
       "         [136., 127.,  84.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2448, 2448, 3), dtype=float32, numpy=\n",
       " array([[[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]],\n",
       " \n",
       "        [[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]],\n",
       " \n",
       "        [[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]],\n",
       " \n",
       "        [[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]],\n",
       " \n",
       "        [[255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         ...,\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.],\n",
       "         [255., 255.,   0.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_height = 2448\n",
    "img_width = 2448\n",
    "process_path(df2.loc[df2['split'] == 'train', 'sat_image_path'][0], df2.loc[df2['split'] == 'train', 'mask_path'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-47d85ff01d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   batch_size=batch_size)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "img_height = 2448\n",
    "img_width = 2448\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'input/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
