{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6c5383-5e60-4b3d-8913-4960c1081ed2",
   "metadata": {},
   "source": [
    "# VGG-16 and Unet using one layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca6554b-ce35-4446-9c6a-21a16d923f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\PhD Classes (Big_files)\\Neural Networks\\Neural Networks\\Project\\2nd_dataset_image\\Cropped_1Channel_Mask\")\n",
    "#os.chdir(r'/home/said.mejia/Projects/Deep_Learning/Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce0d3975-3fbf-4ada-8d55-30399cdaa7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f4cc5ae-7f5b-469d-bc15-cd1bcc8bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5116f-59f1-490b-baa4-1fc173fa54d5",
   "metadata": {},
   "source": [
    "# Changing File names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3eab4-c609-40c6-aadb-3aedc8332db8",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fd38f31-38c8-4853-84f9-76418404d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cropped\\\\test\\\\images\\\\Train_Batch_0_Image_0_Tile_5.png']\n",
      "['Cropped\\\\test\\\\masks\\\\Mask_Batch_0_Image_0_Tile_5.png']\n",
      "2056\n",
      "2056\n"
     ]
    }
   ],
   "source": [
    "direc = \"Cropped_same_name\\\\test\\\\Images\\\\\"\n",
    "reading_images = []\n",
    "reading_masks = []\n",
    "\n",
    "reading_images = glob.glob(r'Cropped\\test\\images\\*.png')\n",
    "reading_masks = glob.glob(r'Cropped\\test\\masks\\*.png')\n",
    "\n",
    "print(reading_images[0:1])\n",
    "print(reading_masks[0:1])\n",
    "\n",
    "print(len(reading_images))\n",
    "print(len(reading_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "257d82b8-af30-47de-b4d9-2b327231a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Batch_0_Image_0_Tile_5.png']\n",
      "2056\n"
     ]
    }
   ],
   "source": [
    "name_images = []\n",
    "for i, r in enumerate(reading_images):\n",
    "    name_images.append(reading_images[i][26:])\n",
    "print(name_images[0:1])\n",
    "print(len(name_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7677c43-59a2-4e3e-8a8e-839c1a9fbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(reading_images):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\test\\\\Images\\\\\" + name_images[i])\n",
    "for i, filename in enumerate(reading_masks):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\test\\\\Masks\\\\\" + name_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "192460da-1a41-4ffc-8760-ea5071d51b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batch_0_Image_0_Tile_5.png'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_images = reading_images[0][26:]\n",
    "name_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94217a39-1522-4167-8c11-3a56ed25928f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a22703b-9c40-4120-a2fc-18eb6ae97970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cropped\\\\train\\\\images\\\\Train_Batch_0_Image_0_Tile_0.png']\n",
      "['Cropped\\\\train\\\\masks\\\\Mask_Batch_0_Image_0_Tile_0.png']\n",
      "8221\n",
      "8221\n"
     ]
    }
   ],
   "source": [
    "direc = \"Cropped_same_name\\\\train\\\\Images\\\\\"\n",
    "reading_images = []\n",
    "reading_masks = []\n",
    "\n",
    "reading_images = glob.glob(r'Cropped\\train\\images\\*.png')\n",
    "reading_masks = glob.glob(r'Cropped\\train\\masks\\*.png')\n",
    "\n",
    "print(reading_images[0:1])\n",
    "print(reading_masks[0:1])\n",
    "\n",
    "print(len(reading_images))\n",
    "print(len(reading_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aed500f5-794c-443d-b977-28dc00293387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Batch_0_Image_0_Tile_0.png']\n",
      "8221\n"
     ]
    }
   ],
   "source": [
    "name_images = []\n",
    "for i, r in enumerate(reading_images):\n",
    "    name_images.append(reading_images[i][27:])\n",
    "print(name_images[0:1])\n",
    "print(len(name_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1600315f-b95c-43d3-b00e-3299c30018f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(reading_images):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\train\\\\Images\\\\\" + name_images[i])\n",
    "for i, filename in enumerate(reading_masks):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\train\\\\Masks\\\\\" + name_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4645c5-9024-4883-9cc2-8576d550a068",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f999a6d9-78a0-4a64-b8b3-a4226d921c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cropped\\\\val\\\\images\\\\Train_Batch_0_Image_0_Tile_13.png']\n",
      "['Cropped\\\\val\\\\masks\\\\Mask_Batch_0_Image_0_Tile_13.png']\n",
      "2570\n",
      "2570\n"
     ]
    }
   ],
   "source": [
    "direc = \"Cropped_same_name\\\\val\\\\Images\\\\\"\n",
    "reading_images = []\n",
    "reading_masks = []\n",
    "\n",
    "reading_images = glob.glob(r'Cropped\\val\\images\\*.png')\n",
    "reading_masks = glob.glob(r'Cropped\\val\\masks\\*.png')\n",
    "\n",
    "print(reading_images[0:1])\n",
    "print(reading_masks[0:1])\n",
    "\n",
    "print(len(reading_images))\n",
    "print(len(reading_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "544ba497-7541-4ad5-bd5a-388f249ec06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Batch_0_Image_0_Tile_13.png']\n",
      "2570\n"
     ]
    }
   ],
   "source": [
    "name_images = []\n",
    "for i, r in enumerate(reading_images):\n",
    "    name_images.append(reading_images[i][25:])\n",
    "print(name_images[0:1])\n",
    "print(len(name_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f777895-9bfd-4686-8ded-5a9b41932ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(reading_images):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\val\\\\Images\\\\\" + name_images[i])\n",
    "for i, filename in enumerate(reading_masks):\n",
    "    os.rename(filename, \"Cropped_same_name\\\\val\\\\Masks\\\\\" + name_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf64eb1-f8e3-44b1-aaba-3cebc5a5f6e0",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0c013-6792-451a-ae7d-7368f6055e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_unet(n_classes=7 ,  input_height=320, input_width=640  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce569a-e9be-4922-8495-0fd6b167268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f546b93-a9f4-4f85-80a3-620cfbb22266",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480fe8b-c542-49a3-9041-7cce8313d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\" , overlay_img=True, show_legends=True,\n",
    "    class_names = [ \"Sky\",    \"Building\", \"Pole\",\"Road\",\"Pavement\",\"Tree\",\"SignSymbol\", \"Fence\", \"Car\",\"Pedestrian\", \"Bicyclist\"]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438af1a-574e-452b-92df-147465bdeebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
