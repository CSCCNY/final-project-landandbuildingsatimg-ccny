{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV ,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-998eaee29039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_IDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_map\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'Initialization'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_IDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_label_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequence' is not defined"
     ]
    }
   ],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs,label_map , img_dir ,mode):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "        self.label_map = image_label_map\n",
    "        self.on_epoch_end()\n",
    "        self.img_dir = img_dir + \"/images\"\n",
    "        self.mask_dir = img_dir + \"/masks\"\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.list_IDs))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index:(index+1)]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y    \n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
    "        if self.mode == \"train\":\n",
    "            # Generate data\n",
    "            X, y = self.load_file(list_IDs_temp)\n",
    "            return X, y\n",
    "        elif self.mode == \"val\":\n",
    "            X, y = self.load_file(list_IDs_temp)\n",
    "            return X, y        \n",
    "        \n",
    "    def load_file(self, id_list):\n",
    "        list_IDs_temp = id_list\n",
    "        for ID in list_IDs_temp:\n",
    "            x_file_path = os.path.join(self.img_dir, ID)\n",
    "            y_file_path = os.path.join(self.mask_dir, self.label_map.get(ID))\n",
    "            # Store sample\n",
    "            X = np.load(x_file_path)\n",
    "            # Store class\n",
    "            y = np.load(y_file_path).astype('float32')\n",
    "        return X, y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train_data_dir = '/home/hgamarro/DeepLearning/HG_space/data/processed/Vegas/train'\n",
    "out_val_data_dir = '/home/hgamarro/DeepLearning/HG_space/data/processed/Vegas/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# train set\n",
    "# ====================\n",
    "all_files = [s for s in os.listdir(out_train_data_dir + \"/images/\") if s.endswith('.npy')]\n",
    "all_files.append([s for s in os.listdir(out_train_data_dir + \"/masks/\") if s.endswith('.npy')] )\n",
    "\n",
    "image_label_map = {\n",
    "        \"image_file_{}.npy\".format(i+1): \"label_file_{}.npy\".format(i+1)\n",
    "        for i in range(int(len(all_files)))}\n",
    "partition = [item for item in all_files if \"image_file\" in item]\n",
    "\n",
    "# ====================\n",
    "# validation set\n",
    "# ====================\n",
    "all_val_files = [s for s in os.listdir(out_val_data_dir + \"/images/\") if s.endswith('.npy')]\n",
    "all_val_files.append([s for s in os.listdir(out_val_data_dir + \"/masks/\") if s.endswith('.npy')] )\n",
    "val_image_label_map = {\n",
    "        \"image_file_{}.npy\".format(i+1): \"label_file_{}.npy\".format(i+1)\n",
    "        for i in range(int(len(all_val_files)))\n",
    "}\n",
    "val_partition = [item for item in all_val_files if \"image_file\" in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(partition,image_label_map,out_train_data_dir, \"train\")\n",
    "val_generator= DataGenerator(val_partition,val_image_label_map,out_val_data_dir, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = datetime.now()\n",
    "print(\"start: \" ,start)\n",
    " \n",
    "\n",
    "history = unet.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(train_generator), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=len(val_generator),\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "end = datetime.now()\n",
    "print(\"end: \" ,end)\n",
    "print(\"\\nTime Taken for testing: %s\" % (end-start))\n",
    "\n",
    "model.save(model_andor_weight_path+\"model_unet5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3, \n",
    "                                    method = \"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:,1] # score = probab of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimization\n",
    "parameter_gridsearch = {\n",
    "                 'max_depth' : [3, 4],  #depth of each decision tree\n",
    "                 'n_estimators': [50, 20],  #count of decision tree\n",
    "                 'max_features': ['sqrt', 'auto', 'log2'],      \n",
    "                 'min_samples_split': [2],      \n",
    "                 'min_samples_leaf': [1, 3, 4],\n",
    "                 'bootstrap': [True, False],\n",
    "                 }\n",
    "# RF classification\n",
    "\n",
    "randomforest = randomForestClassifier()\n",
    "crossvalidation = StratifiedKFold(train[0::,0] , n_folds=5)\n",
    "\n",
    "gridsearch = GridSearchCV(randomforest,             #grid search for algorithm optimization\n",
    "                               scoring='accuracy',\n",
    "                               param_grid=parameter_gridsearch,\n",
    "                               cv=crossvalidation)\n",
    "\n",
    "\n",
    "#gridsearch.fit(train[0::,1::], train[0::,0])    #train[0::,0] is as target\n",
    "gridsearch.fit(train[0::,1::], train[0::,0])    #train[0::,0] is as target\n",
    "model = gridsearch\n",
    "parameters = gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
